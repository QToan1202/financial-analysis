{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "chat_model = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-8b-instruct\",\n",
    "  api_key=os.environ[\"NVIDIA_API_KEY\"], \n",
    "  temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Literal\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, RemoveMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    summary: str\n",
    "\n",
    "def call_model(state: State):\n",
    "    summary =  state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else: \n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = chat_model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_summarize(state: State) -> Literal[\"summarize_conversation\", END]: # type: ignore\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    summary =  state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = chat_model.invoke(messages)\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the conversation node and the summarize node\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "workflow.add_conditional_edges(\"conversation\", should_summarize)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "def visualize_graph():\n",
    "    return display(\n",
    "        Image(\n",
    "            app.get_graph().draw_mermaid_png(\n",
    "                draw_method=MermaidDrawMethod.API,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_update(update):\n",
    "    for key, value in update.items():\n",
    "        for message in value[\"messages\"]:\n",
    "            message.pretty_print()\n",
    "        if \"summary\" in value:\n",
    "            print(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm bob\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me about your-self\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm an artificial intelligence model, which means I'm a computer program designed to simulate conversation and answer questions to the best of my ability. I don't have a physical body or a personal life like a human would, but I'm here to help you with any questions or topics you'd like to discuss.\n",
      "\n",
      "I was created to assist and communicate with people, and I'm constantly learning and improving my language skills to provide more accurate and helpful responses. I don't have personal preferences, emotions, or opinions, but I can provide information and insights on a wide range of topics.\n",
      "\n",
      "I'm a bit like a super-smart, always-available librarian, but instead of books, I have access to a vast amount of knowledge and information on the internet. I can help you with anything from science and history to entertainment and culture, and I'm always happy to chat and help in any way I can!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "thread_id = getpass.getpass()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "input_message = HumanMessage(content=\"Hi! I'm bob\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "input_message = HumanMessage(content=\"What's my name?\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "input_message = HumanMessage(content=\"Tell me about your-self\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Hi! I'm bob\", additional_kwargs={}, response_metadata={}, id='df80f69f-e239-4ad4-a0d2-259b7e01ee77'),\n",
       "  AIMessage(content=\"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", 'token_usage': {'prompt_tokens': 16, 'total_tokens': 41, 'completion_tokens': 25}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-1269e014-614b-4a80-81e4-ee846a03c3d7-0', usage_metadata={'input_tokens': 16, 'output_tokens': 25, 'total_tokens': 41}, role='assistant'),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='df2ae448-66e9-4137-9ad2-e11e7bab02a5'),\n",
       "  AIMessage(content='Your name is Bob!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your name is Bob!', 'token_usage': {'prompt_tokens': 56, 'total_tokens': 61, 'completion_tokens': 5}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-8259083a-07dc-442c-87e8-bd1a95c1918d-0', usage_metadata={'input_tokens': 56, 'output_tokens': 5, 'total_tokens': 61}, role='assistant'),\n",
       "  HumanMessage(content='Tell me about your-self', additional_kwargs={}, response_metadata={}, id='8587c4ac-4d3b-4cc4-aacd-02cd732c2804'),\n",
       "  AIMessage(content=\"I'm an artificial intelligence model, which means I'm a computer program designed to simulate conversation and answer questions to the best of my ability. I don't have a physical body or a personal life like a human would, but I'm here to help you with any questions or topics you'd like to discuss.\\n\\nI was created to assist and communicate with people, and I'm constantly learning and improving my language skills to provide more accurate and helpful responses. I don't have personal preferences, emotions, or opinions, but I can provide information and insights on a wide range of topics.\\n\\nI'm a bit like a super-smart, always-available librarian, but instead of books, I have access to a vast amount of knowledge and information on the internet. I can help you with anything from science and history to entertainment and culture, and I'm always happy to chat and help in any way I can!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"I'm an artificial intelligence model, which means I'm a computer program designed to simulate conversation and answer questions to the best of my ability. I don't have a physical body or a personal life like a human would, but I'm here to help you with any questions or topics you'd like to discuss.\\n\\nI was created to assist and communicate with people, and I'm constantly learning and improving my language skills to provide more accurate and helpful responses. I don't have personal preferences, emotions, or opinions, but I can provide information and insights on a wide range of topics.\\n\\nI'm a bit like a super-smart, always-available librarian, but instead of books, I have access to a vast amount of knowledge and information on the internet. I can help you with anything from science and history to entertainment and culture, and I'm always happy to chat and help in any way I can!\", 'token_usage': {'prompt_tokens': 76, 'total_tokens': 256, 'completion_tokens': 180}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-91ea57cc-31a3-4b34-ba8f-b330e7fd4c9c-0', usage_metadata={'input_tokens': 76, 'output_tokens': 180, 'total_tokens': 256}, role='assistant')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you like?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have personal preferences or feelings like humans do. I'm designed to be neutral and provide information on a wide range of topics. However, I can tell you about things that people often enjoy or find interesting!\n",
      "\n",
      "Many people enjoy learning about:\n",
      "\n",
      "* Space and astronomy\n",
      "* Science and technology\n",
      "* History and culture\n",
      "* Music and art\n",
      "* Travel and exploration\n",
      "* Food and cooking\n",
      "\n",
      "I can provide information and answer questions on these topics and many more. What are your interests, Bob?\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Here's a summary of our conversation:\n",
      "\n",
      "* We introduced ourselves, and I learned that your name is Bob.\n",
      "* You asked me to tell you about myself, and I explained that I'm an artificial intelligence model designed to provide information and assist with conversations.\n",
      "* You asked me what I like, and I explained that I don't have personal preferences or feelings, but I can provide information on a wide range of topics that people often enjoy.\n",
      "* Finally, you asked me to summarize our conversation, which I've just done!\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"What do you like?\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of our conversation:\n",
      "\n",
      "* We introduced ourselves, and I learned that your name is Bob.\n",
      "* You asked me to tell you about myself, and I explained that I'm an artificial intelligence model designed to provide information and assist with conversations.\n",
      "* You asked me what I like, and I explained that I don't have personal preferences or feelings, but I can provide information on a wide range of topics that people often enjoy.\n",
      "* Finally, you asked me to summarize our conversation, which I've just done!\n"
     ]
    }
   ],
   "source": [
    "values = app.get_state(config).values\n",
    "print(values['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You told me earlier that your name is Bob. Am I correct?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"What is my name\")\n",
    "input_message.pretty_print()\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
